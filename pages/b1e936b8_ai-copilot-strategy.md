# https://www.moveworks.com/insights/ai-copilot-strategy

Forrester names Moveworks a leader in Chatbot for IT operations. Read the report today.

Moveworks named a Forrester leader in Chatbot for IT operations. 

Schedule a meeting with a Moveworks representative and learn how we can help reduce employee issue resolution from days to seconds.

By checking this box, I agree to receive company news and updates. Learn more in the Privacy Policy.

Thank you.

A member of the Moveworks team will be in touch within the next 24 hours.



  Close this modal
  



Vaibhav Nivargi, CTO


The rapid rise of ChatGPT has ignited a race to adopt smarter and more powerful AI models across the enterprise. 

Companies are increasingly exploring what are coming to be known as "AI copilots" to boost efficiency and performance across various tasks. With the continuous advancement of these copilots, businesses must have a clear strategy in place to capitalize on their potential. 

We introduced a four-tier AI copilot framework during our Moveworks Live event to clarify what you should consider when implementing an AI copilot solution in your business and what tech investment level you’ll need to make to successfully achieve your goals.

Today, I’ll dive into this framework to help you determine your copilot strategy, answering questions such as:

 

>> Learn how to build an AI copilot strategy that works for you. Check out our webinar!

 

An AI copilot is a conversational interface that uses large language models (LLMs) to automate tasks and retrieve information. By leveraging LLMs, copilots understand and respond to human language effectively, making it easier for users to interact with and navigate digital platforms.

As AI continues to develop rapidly, copilots will play an increasingly vital role in helping users streamline their tasks and better use their digital resources. In light of this, defining a well-structured copilot strategy becomes essential for businesses aiming to harness the full potential of AI technology. 

 

Before developing an AI copilot strategy, you need to understand what it takes to build a copilot-like experience into your enterprise. There is a vast difference between ChatGPT and an enterprise copilot platform that is fully integrated within an organization. This is not to say that ChatGPT isn’t helpful. It is incredibly helpful for certain use cases. But it’s limited in its ability.

For a copilot to own more enterprise-focused tasks, you need a less general, more tailored approach that can manage:

Given the above, it should be clear that incorporating a copilot experience into your organization takes considerable effort. While some use cases might be lighter lifts, others will require heavy, long-term maintenance. The scope of the problem you’re trying to solve will require varying degrees of investment. For example, using AI to provide enterprise-wide support will, by definition, need a much better understanding of and investment in the bullets above than using AI to write web copy. 



Figure 1: When looking at AI copilot use cases, we start to see the relationship between the scope of the problem and the investment required to solve it, enabling decision-makers to make informed choices when embracing LLMs for their organizations.

 

This is to say that an AI copilot is not something you can build and maintain on your own, particularly if you want to expand its functionality across the enterprise. Investing in the right partner with the right resources is the key to successfully implementing a helpful and efficient AI copilot.

 

The four-tiered AI copilot strategy framework

We created a four-tiered framework to help leaders better understand the technology and investments necessary to integrate LLMs into production environments.

By grasping the nuances between various AI copilots and their unique capabilities and limitations, you will be better equipped to create a compelling and tailored strategy for your organization.

 

A tier-one copilot involves a basic API call of a large language model (LLM). In this approach, prompt engineering is used to help a user access general information, and the copilot is primarily aimed at improving efficiency across high-level use cases.

A tier-one copilot simplifies various everyday tasks by leveraging AI-powered assistance. Some common use cases include:



Figure 2: Tier-one copilots rely on basic LLM integrations to solve small-scale enterprise challenges.

Tier-one copilots are relatively easy to kick off, requiring minimal resources and offering a low barrier to entry, making them an attractive starting point for organizations exploring AI tools. 

Launching the copilot boils down to accessing an LLM, such as GPT-4. LLM-as-a-service providers, like Hugging Face and OpenAI, make this process even more accessible. You simply subscribe to a reliable API provider for your chosen LLM and integrate their API into your software or platform. This streamlined approach needs little beyond developer resources dedicated to implementing the API integration, ensuring a smooth and cost-effective way to introduce AI-driven assistance into your organization.

Prompt engineering is a crucial machine learning technique that bolsters the effectiveness of tier-one copilots. 

By thoughtfully crafting and refining user prompts based on previous interactions, you can elicit more accurate model responses that better align with users' needs. While prompt engineering is more art than science, advanced tactics such as auto-prompting and prompt tuning can significantly enhance your tier-one copilot's performance, taking it one step closer to the desired outcome.

 

A tier-two copilot is a customized implementation of an LLM fine-tuned and grounded with an organization's domain-specific data. Unlike off-the-shelf models trained on general internet data, tier-two copilots are designed to perform tasks and generate answers that cater to specialized areas.

A tier-two copilot is better prepared to manage some domain-specific tasks. Some common use cases include:



Figure 3: Tier-two copilots offer more customized LLM implementations.

Developing a tier-two copilot involves a substantial upfront investment in resources and expertise. Key elements include pre-trained models, supporting infrastructure such as GPUs, and a skilled team of developers and machine learning engineers capable of selecting a suitable pre-trained model, like LLaMA, RoBERTa, MPNet, or Flan-T5, and fine-tuning it with the organization's domain data for a more customized LLM implementation.

Annotation is also critical for this more focused approach. And while the annotation process can commence with external service providers like Scale.ai, it’s essential to transition in-house as you advance to higher tiers with increased domain specificity and scrutiny. 

Although tier-two copilots demand more resources and investment than their tier-one counterparts, the payoff is a high-performance, domain-specific AI solution that tackles your organization's unique challenges.

Optimizing the performance of an AI-driven copilot necessitates leveraging key machine learning techniques such as fine-tuning, grounding, and retrieval augmentation. 

Fine-tuning involves adapting the chosen base model to a specific task using labeled, domain-specific data. Then, both grounding and retrieval augmentation can enhance the copilot's factuality and accuracy by utilizing contextual information from user data, unique entities, query patterns, and curated documents. 

These techniques work in harmony to deliver tailored AI-driven assistance that caters to an organization's unique needs and challenges, providing highly relevant, meaningful, and contextually accurate results.

 

A tier-three copilot involves chaining multiple LLMs together, creating sophisticated pipelines optimized for multi-step use cases that leverage the strengths and capabilities of each LLM involved. As a result, the tier-three copilot can provide tailored assistance and solutions for intricate domain-specific challenges.

By incorporating multiple LLMs and advanced techniques, tier-three copilots can tackle a broader range of use cases, enhance productivity and efficiency, and address challenges in more sophisticated domains. Some common use cases include:



Figure 4: Tier-three copilots bring together multiple LLMs to manage complex use cases.

To get started with a tier-three copilot, there are several key elements and investments you need to consider. First, you must create a multi-LLM stack consisting of various pre-trained models designed to work together for more complex tasks. It is essential to have connectors in place to enable seamless system integrations and facilitate the interactions between different LLMs.

As is also the case with tier-two copilots, investing in fine-tuning is crucial for optimizing the models in the multi-LLM stack. Along with this, system integrations help the copilot assimilate into your organization's existing workflows and automation.

Allocating resources for annotators to generate high-quality domain-specific data will ensure improved performance for your copilot. Likewise, assembling dedicated AI and machine learning teams is vital for developing, implementing, and optimizing the tier-three copilot.

Developing a robust tier-three copilot capable of tackling complex, multi-step tasks involves several advanced machine learning techniques. 

First, chaining allows for the seamless integration of multiple LLMs in a pipeline, tapping into the combined strengths of each model for superior performance. This is further complemented by entity extraction and linking, which enable the identification and correlation of crucial data points within the input context, providing richer layers of information for the copilot.

Connectors also play a vital role as intermediaries between the LLM stack and existing systems, facilitating efficient communication and enhancing the overall coherence of the AI-driven solution. By incorporating these sophisticated techniques, tier-three copilots can effectively address intricate use cases, driving productivity and efficiency within an organization.

Tier-four copilots work to address the challenges inherent in providing extensible employee support and facilitating autonomous decision-making.

As a sophisticated LLM system specifically designed for enterprise-wide deployment, these tier-four copilots encompass advanced features like a reasoning engine, analytics, security, and privacy, as well as out-of-the-box connectors catering to the demanding requirements of large organizations. 

A tier-four copilot can handle issues across multiple functions, channels, languages, and departments. Here are just a handful of examples:

Figure 5: Tier-four copilots are specifically designed for enterprise-wide deployment.

Accuracy and factuality are of paramount importance when incorporating a tier-four copilot in enterprise settings such as legal, corporate development, or finance departments. Organizations must invest in multiple specialized teams to effectively implement a tier-four copilot, including design, UX, annotation, machine learning, systems integration, and security compliance and privacy infrastructure.

Advanced reasoning techniques further enhance the performance of a tier-four copilot, enabling it to tackle complex problems and improve employee productivity. Organizations can leverage robust language models to optimize their decision-making processes and streamline operations across departments by grounding the copilot to specific use cases.

As organizations increasingly rely on language models, powerful decision-making and reasoning capabilities have become indispensable. As mentioned, generalized LLMs struggle to navigate complex challenges as more use cases, systems, and teams are added. Tier-four copilots, with chained models explicitly designed for decision-making and reasoning, are essential to bridge this gap.

However, as use cases expand, managing and scaling these models without compromising performance is a complex task for machine learning engineers and data scientists. Models must be agile, delivering accurate results even as they evolve.

The rapid growth in system complexity and ever-changing use cases requires deep integrations in systems across the enterprise. Tier-four copilots must be adept at scaling quickly and adapting to new environments. These integrations allow for improved information flow across various systems in an organization for better reasoning capabilities.

 

Moveworks sets itself apart as a tier-four copilot by both harnessing hundreds of machine learning models, specifically fine-tuned to enterprise data, and deeply integrating with the organization’s disparate tech stack to fully connect the enterprise ecosystem.

By partnering with Moveworks, organizations can access accurate, verifiable information through controlled outputs that leverage proprietary data for precision and relevance.

Extensibility is at the heart of Moveworks, enabling users to expand the copilot into new domains and use cases. The recently launched Creator Studio embodies this concept, providing the Moveworks copilot with extraordinary capabilities tailored to the needs of growing enterprises.

Our commitment to retaining task-level precision is critical for delivering a high level of service and addressing complex enterprise challenges. And our domain expertise, extensibility, and customization position us as a leading tier-four copilot, empowering organizations to leverage advanced language models to improve efficiency, accuracy, and innovation in today's competitive business landscape.



Figure 6: The Moveworks enterprise copilot platform integrates with every business system, meaning it can support any use case across any department.

 

It goes without saying that now is an exciting time to build using large language models. We’re at the beginning of a massive enterprise transformation driven by new AI tools like copilots. And as businesses adopt these cutting-edge solutions, having a well-defined copilot strategy is paramount to success.

Throughout this article, we've explored our four-tier AI copilot framework to help you better understand the investment levels and implementation considerations when integrating AI copilots into your business. By assessing your organization's unique requirements and goals, you can align the appropriate copilot tier to maximize the benefits of these advanced AI models.

In an ever-evolving business environment, staying ahead of the curve is vital. A deep understanding of AI copilots and a commitment to developing an effective strategy will propel your organization to new heights. It’s time to seize the opportunities offered by this technology and empower your people with innovative AI copilot solutions.

See the rest of Moveworks Live. Check it out!


          Discover how AIOps transforms IT operations from reactive to proactive. Understand the AIOps revolution and shift from firefighters to innovators.
        


          Learn how AI & automation can immediately provide ROI and elevate service experience at scale for federal and state government and the public sector as a whole.
        


          3 key takeaways from the Forrester Technology & Innovation Summit: 1. Make generative AI your #1 priority. 2. Balance Risk 3. Deploy Copilots. Read the recap.
        


          Conversational AI is improving healthcare delivery by automating tasks, surfacing knowledge, and supporting staff. Learn how leading providers use this technology.
        


          From spelling correction to intent classification, get to know the large language models that power Moveworks' conversational AI platform.
        


          AI is transforming IT operations analytics (ITOA). Here are the key benefits and challenges of implementing AI-driven ITOA, including real-world examples.
        



![Image](https://www.moveworks.com/hubfs/img/site/qr-demo.png)
![](https://www.moveworks.com/hubfs/00-img-blog-hero-Copilot-Strategy-1600x900.png)
![](https://www.moveworks.com/hubfs/00-img-blog-hero-Copilot-Strategy-1600x900.png)
![Screenshot 2023-08-25 at 2.51.05 PM](https://www.moveworks.com/hs-fs/hubfs/Screenshot%202023-08-25%20at%202.51.05%20PM.png?width=760&height=392&name=Screenshot%202023-08-25%20at%202.51.05%20PM.png)
![Screenshot 2023-08-25 at 2.52.47 PM](https://www.moveworks.com/hs-fs/hubfs/Screenshot%202023-08-25%20at%202.52.47%20PM.png?width=760&height=393&name=Screenshot%202023-08-25%20at%202.52.47%20PM.png)
![Screenshot 2023-08-25 at 2.53.38 PM](https://www.moveworks.com/hs-fs/hubfs/Screenshot%202023-08-25%20at%202.53.38%20PM.png?width=760&height=414&name=Screenshot%202023-08-25%20at%202.53.38%20PM.png)
![Screenshot 2023-08-25 at 2.54.18 PM](https://www.moveworks.com/hs-fs/hubfs/Screenshot%202023-08-25%20at%202.54.18%20PM.png?width=760&height=422&name=Screenshot%202023-08-25%20at%202.54.18%20PM.png)
![Screenshot 2023-08-25 at 2.55.21 PM](https://www.moveworks.com/hs-fs/hubfs/Screenshot%202023-08-25%20at%202.55.21%20PM.png?width=742&height=386&name=Screenshot%202023-08-25%20at%202.55.21%20PM.png)
![Image](https://www.moveworks.com/hubfs/image-png-Jun-16-2023-06-53-08-8232-PM.png)
![Image](https://www.moveworks.com/hs-fs/hubfs/AIOps-featured-image.png?length=50&name=AIOps-featured-image.png)
![Image](https://www.moveworks.com/hs-fs/hubfs/Public-Sector-Convo-AI.png?length=50&name=Public-Sector-Convo-AI.png)
![Image](https://www.moveworks.com/hs-fs/hubfs/Forrester%20T%26I%20%281%29.png?length=50&name=Forrester%20T&I%20%281%29.png)
![Image](https://www.moveworks.com/hs-fs/hubfs/healthcare-test.png?length=50&name=healthcare-test.png)
![Image](https://www.moveworks.com/hs-fs/hubfs/Moveworks_LLM_Feature.png?length=50&name=Moveworks_LLM_Feature.png)
![Image](https://www.moveworks.com/hs-fs/hubfs/ITOA_feature.png?length=50&name=ITOA_feature.png)
